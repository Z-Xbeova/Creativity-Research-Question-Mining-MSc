# Towards supporting creativity research - question mining

## Contents

Data (in data directory):

- bloom: Exam Question Dataset;
- jokes: Question-Answer Jokes;
- squad: Stanford Question Answering Dataset;
- ~~sta: STA interviews~~ (unavailable publicly);
- tatman: R. Tatman's Question-Answer Dataset.

Other subdirectories:

- ~~glove_vectors: GloVe vectors generated for computation of the MAD metric (Answer-Based Assessment) and SeedTopicMine topic classification (Topic Study)~~ (not included due to size);
- information: values of answer-based metrics for R. Tatman's Question-Answer Dataset, Question-Answer Jokes, and Stanford Question Answering Dataset;
- transformers\_cache: empty folder, used to store sentence transformers cache during running experiments.

Source code files:

- preprocess.ipynb -- preprocessing of Exam Question Dataset, R. Tatman's Question-Answer Dataset, Question-Answer Jokes, and Stanford Question Answering Dataset;
- TA\_prepare\_learning.py -- preparation of data for the classification model training in the Taxonomy Assessment experiment;
- TA\_perform\_learning.py -- classification model training in the Taxonomy Assessment experiment;
- TA\_predictions.ipynb -- generation of Bloom's Taxonomy levels for questions in R. Tatman's Question-Answer Dataset, Question-Answer Jokes, Stanford Question Answering Dataset, and STA interviews;
- TA\_analysis.ipynb -- analysis of questions in R. Tatman's Question-Answer Dataset, Question-Answer Jokes, and Stanford Question Answering Dataset by predicted Bloom's Taxonomy level;
- TA\_explanations.ipynb -- generation of explanations for classification model predictions on simple examples, as a part of the Taxonomy Assessment experiment;
- TA\_lime\_display.py -- graphic presentation of prediction explanations generated in TA\_explanations.ipynb;
- AbA\_compute\_metrics.ipynb -- computation of answer-based question creativity metrics for questions in R. Tatman's Question-Answer Dataset, Question-Answer Jokes, and Stanford Question Answering Dataset, for the Answer-Based Assessment experiment;
- AbA\_analysis.ipynb -- analysis of metric values computed in AbA\_compute\_metrics.ipynb;
- Topic\_Study.ipynb -- pipeline of the Topic Study experiment;
- TsS\_metrics.ipynb -- computation of answer-based question creativity metrics for STA interviews, as a part of the Timestamp Study experiment;
- TsS\_graphs.ipynb -- generation of plots for the Timestamp Study experiment.

Other files:

- 1-1000.txt -- 1000 most common words;
- explanations.csv -- simple examples from R. Tatman's Question-Answer Dataset, Question-Answer Jokes, and Stanford Question Answering Dataset with predicted Bloom's Taxonomy levels;
- exps.txt -- LIME explanations of Bloom's Taxonomy level predictions for questions in explanations.csv;
- history.csv -- classification model training process history;
- requirements.txt -- Python packages required to run the source code;
- roberta_cnn.keras -- trained CNN part of the RoBERTa/CNN-based classification model to predict Bloom's Taxonomy level of a question;
- simple.xlsx -- Microsoft Excel sheet to extract metric values for questions in explanations.csv
- tatmancategories.csv -- topic categories of source articles for R. Tatman's Question-Answer Dataset;
- topics_results.txt -- topics and seed words generated by the SeedTopicMine algorithm for the Topic Study experiment.
